@misc{agarwal2020multivariate,
	title={On Multivariate Singular Spectrum Analysis and its Variants},
	author={Anish Agarwal and Abdullah Alomar and Devavrat Shah},
	year={2020},
	eprint={2006.13448},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@article{PhysRevE.84.036206,
	title = {Multivariate singular spectrum analysis and the road to phase synchronization},
	author = {Groth, Andreas and Ghil, Michael},
	journal = {Phys. Rev. E},
	volume = {84},
	issue = {3},
	pages = {036206},
	numpages = {10},
	year = {2011},
	month = {Sep},
	publisher = {American Physical Society},
	doi = {10.1103/PhysRevE.84.036206},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.84.036206}
}

@Article{app7040418,
	AUTHOR = {Yang, Dan and Yi, Cancan and Xu, Zengbin and Zhang, Yi and Ge, Mao and Liu, Changming},
	TITLE = {Improved Tensor-Based Singular Spectrum Analysis Based on Single Channel Blind Source Separation Algorithm and Its Application to Fault Diagnosis},
	JOURNAL = {Applied Sciences},
	VOLUME = {7},
	YEAR = {2017},
	NUMBER = {4},
	ARTICLE-NUMBER = {418},
	URL = {https://www.mdpi.com/2076-3417/7/4/418},
	ISSN = {2076-3417},
	ABSTRACT = {To solve the problem of multi-fault blind source separation (BSS) in the case that the observed signals are under-determined, a novel approach for single channel blind source separation (SCBSS) based on the improved tensor-based singular spectrum analysis (TSSA) is proposed. As the most natural representation of high-dimensional data, tensor can preserve the intrinsic structure of the data to the maximum extent. Thus, TSSA method can be employed to extract the multi-fault features from the measured single-channel vibration signal. However, SCBSS based on TSSA still has some limitations, mainly including unsatisfactory convergence of TSSA in many cases and the number of source signals is hard to accurately estimate. Therefore, the improved TSSA algorithm based on canonical decomposition and parallel factors (CANDECOMP/PARAFAC) weighted optimization, namely CP-WOPT, is proposed in this paper. CP-WOPT algorithm is applied to process the factor matrix using a first-order optimization approach instead of the original least square method in TSSA, so as to improve the convergence of this algorithm. In order to accurately estimate the number of the source signals in BSS, EMD-SVD-BIC (empirical mode decomposition—singular value decomposition—Bayesian information criterion) method, instead of the SVD in the conventional TSSA, is introduced. To validate the proposed method, we applied it to the analysis of the numerical simulation signal and the multi-fault rolling bearing signals.},
	DOI = {10.3390/app7040418}
}

@INPROCEEDINGS{6661921,
	author={Kouchaki, Samaneh and Sanei, Saeid},
	booktitle={2013 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)}, 
	title={Tensor based singular spectrum analysis for nonstationary source separation}, 
	year={2013},
	volume={},
	number={},
	pages={1-5},
	doi={10.1109/MLSP.2013.6661921}}

@ARTICLE{6834801,
	author={Kouchaki, Samaneh and Sanei, Saeid and Arbon, Emma L. and Dijk, Derk-Jan},
	journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
	title={Tensor Based Singular Spectrum Analysis for Automatic Scoring of Sleep EEG}, 
	year={2015},
	volume={23},
	number={1},
	pages={1-9},
	doi={10.1109/TNSRE.2014.2329557}}


@ARTICLE{10122507,
	author={Fu, Hang and Sun, Genyun and Zhang, Aizhu and Shao, Baojie and Ren, Jinchang and Jia, Xiuping},
	journal={IEEE Transactions on Geoscience and Remote Sensing}, 
	title={Tensor Singular Spectrum Analysis for 3-D Feature Extraction in Hyperspectral Images}, 
	year={2023},
	volume={61},
	pages={1-14},
	doi={10.1109/TGRS.2023.3272669}}

@article{FU2023115,
	title = {Three-dimensional singular spectrum analysis for precise land cover classification from UAV-borne hyperspectral benchmark datasets},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	volume = {203},
	pages = {115-134},
	year = {2023},
	issn = {0924-2716},
	doi = {https://doi.org/10.1016/j.isprsjprs.2023.07.013},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271623001946},
	author = {Hang Fu and Genyun Sun and Li Zhang and Aizhu Zhang and Jinchang Ren and Xiuping Jia and Feng Li},
	keywords = {Precise classification, UAV-borne HSI, Feature extraction, 3DSSA, QUH dataset},
	abstract = {The precise classification of land covers with hyperspectral imagery (HSI) is a major research-focused topic in remote sensing, especially using unmanned aerial vehicle (UAV) systems as the abundant data sources have brought severe intra-class spectral variability and high spatial heterogeneity challenges, making precise classification difficult. To this end, a novel three-dimensional singular spectrum analysis (3DSSA) method is proposed for the 3D feature extraction of HSI. It aims to construct a low-rank trajectory tensor containing global and local features and extract both spectral discrimination features and spatial contextual features in conjunction with tensor singular value decomposition (t-SVD). To reduce the risk of tensor operations exceeding memory on large-scale HSI data, the extended regional clustering (RC) 3DSSA framework (RC-3DSSA) is proposed for precise HSI classification. RC-3DSSA uses RC processing to alleviate the scale diversity and further applies 3DSSA to tackle issues of intra-class spectral variability and spatial heterogeneity. In order to effectively evaluate the performance of RC-3DSSA, a new challenging classification dataset namely the Qingdao UAV-borne HSI (QUH) dataset was further built. It consists of three sub-datasets: QUH-Tangdaowan, QUH-Qingyun, and QUH-Pingan, which are freely available as benchmarks for precise land cover classification. The experimental results on QUH and two publicly available datasets show that the RC-3DSSA can accurately distinguish ground objects and reliably map their distribution when benchmarked with ten state-of-the-art methods. Specifically, the overall accuracies achieved are 86.62, 87.51, and 87.35 under 10 spatially disjoint training samples for the three UAV-borne HSI datasets, respectively, providing the best performance.}
}

@article{Box_Jenkins_methodology,
	author = {Tunnicliffe Wilson, Granville},
	year = {2016},
	month = {03},
	pages = {n/a-n/a},
	title = {Time Series Analysis: Forecasting and Control,5th Edition, by George E. P. Box, Gwilym M. Jenkins, Gregory C. Reinsel and Greta M. Ljung, 2015. Published by John Wiley and Sons Inc., Hoboken, New Jersey, pp. 712. ISBN: 978-1-118-67502-1},
	volume = {37},
	journal = {Journal of Time Series Analysis},
	doi = {10.1111/jtsa.12194}
}

@book{hamilton1994time,
	title={Time Series Analysis},
	author={Hamilton, J.D.},
	number={т. 10},
	isbn={9780691042893},
	lccn={lc93004958},
	series={Book collections on Project MUSE},
	url={https://books.google.ru/books?id=B8_1UBmqVUoC},
	year={1994},
	publisher={Princeton University Press}
}

@book{3b1355aedd1041f1853e609a410576f3,
	title = "Forecasting: Principles and Practice",
	author = "Hyndman, {Robin John} and George Athanasopoulos",
	year = "2018",
	language = "English",
	publisher = "OTexts",
	address = "Australia",
	edition = "2nd",
}

@book{Greene2003Econometric,
	added-at = {2018-06-18T21:23:34.000+0200},
	author = {Greene, William H.},
	biburl = {https://www.bibsonomy.org/bibtex/28ded70f02507563c15bfdd8dd2208e12/pbett},
	citeulike-article-id = {14358797},
	citeulike-attachment-1 = {Greene_EconometricAnalysis_5thEd_2002.pdf; /pdf/user/pbett/article/14358797/1109751/Greene_EconometricAnalysis_5thEd_2002.pdf; 555dcbdff6a834feae11ed60d48b3ca8f6e3c5b3},
	citeulike-linkout-0 = {http://pages.stern.nyu.edu/~wgreene/Text/econometricanalysis.htm},
	comment = {(private-note)Used as the reference for the statsmodels python package for prediction intervals - see p111.},
	edition = {Fifth},
	file = {Greene_EconometricAnalysis_5thEd_2002.pdf},
	interhash = {fb74ec9471c97eb32162f303c71262e1},
	intrahash = {8ded70f02507563c15bfdd8dd2208e12},
	isbn = {0-13-066189-9},
	keywords = {textbook statistics economics},
	posted-at = {2017-05-17 18:18:23},
	priority = {2},
	publisher = {Pearson Education},
	timestamp = {2018-06-22T18:36:55.000+0200},
	title = {Econometric Analysis},
	url = {http://pages.stern.nyu.edu/~wgreene/Text/econometricanalysis.htm},
	year = 2003
}

@book{enders2010applied,
	title={Applied Econometric Time Series},
	author={Enders, W. and John Wiley \& Sons},
	isbn={9788126543915},
	lccn={2010483073},
	series={Wiley series in probability and statistics},
	url={https://books.google.ru/books?id=vzJ0CgAAQBAJ},
	year={2010},
	publisher={Wiley}
}

@inbook{ecfb9dc578be43ae9ee8fc88b8ff9151,
	title = "SSA-based approaches to analysis and forecast of multidimensional time series",
	author = "D. Stepanov and N. Golyandina",
	year = "2005",
	pages = "293--298",
	booktitle = "Proceedings of the 5th St.Petersburg Workshop on Simulation",
}

@misc{chen2018neural,
	title={Neural Ordinary Differential Equations},
	author={Ricky T. Q. Chen and Yulia Rubanova and Jesse Bettencourt and David Duvenaud},
	year={2018},
	eprint={1806.07366},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@Inbook{Tsonis2018,
	author="Tsonis, Anastasios A.
	and Deyle, Ethan R.
	and Ye, Hao
	and Sugihara, George",
	editor="Tsonis, Anastasios A.",
	title="Convergent Cross Mapping: Theory and an Example",
	bookTitle="Advances in Nonlinear Geosciences",
	year="2018",
	publisher="Springer International Publishing",
	address="Cham",
	pages="587--600",
	abstract="In this review paper we present the basic principles behind convergent cross mapping, a new causality detection method, as well as an example to demonstrate it.",
	isbn="978-3-319-58895-7",
	doi="10.1007/978-3-319-58895-7_27",
	url="https://doi.org/10.1007/978-3-319-58895-7_27"
}

@book{x11,
	author = {Dagum, Estela and Bianconcini, Silvia},
	year = {2016},
	month = {08},
	pages = {},
	title = {Seasonal Adjustment Methods and Real Time Trend-Cycle Estimation},
	isbn = {978-3-319-31820-2}
}

@article{cleveland90,
	added-at = {2009-10-28T04:42:52.000+0100},
	author = {Cleveland, Robert B. and Cleveland, William S. and McRae, Jean E. and Terpenning, Irma},
	biburl = {https://www.bibsonomy.org/bibtex/24bf4893a61f6e30b2dbf7f37884295ed/jwbowers},
	citeulike-article-id = {106881},
	date-added = {2007-09-03 22:45:16 -0500},
	date-modified = {2007-09-03 22:45:16 -0500},
	interhash = {a8931b8eac108ccff1bb30b75130aac9},
	intrahash = {4bf4893a61f6e30b2dbf7f37884295ed},
	journal = {Journal of Official Statistics},
	keywords = {graphical_methods statistics},
	pages = {3--73},
	timestamp = {2009-10-28T04:43:05.000+0100},
	title = {STL: A Seasonal-Trend Decomposition Procedure Based on Loess (with Discussion)},
	volume = 6,
	year = 1990
}

@incollection{citeulike:2735031,
	abstract = {{Without Abstract}},
	added-at = {2017-06-29T07:13:07.000+0200},
	address = {Berlin},
	author = {Takens, Floris},
	biburl = {https://www.bibsonomy.org/bibtex/239782de7849c029ffdd9d2d7e00c457e/gdmcbain},
	booktitle = {Dynamical Systems and Turbulence, Warwick 1980},
	chapter = 21,
	citeulike-article-id = {2735031},
	citeulike-attachment-1 = {takens_81_detecting.pdf; /pdf/user/gdmcbain/article/2735031/1026091/takens_81_detecting.pdf; 4039236d89b682a2ab7aa9baaa4057707161d9be},
	citeulike-linkout-0 = {http://dx.doi.org/10.1007/bfb0091924},
	citeulike-linkout-1 = {http://www.springerlink.com/content/b254x77553874745},
	citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/BFb0091924},
	doi = {10.1007/bfb0091924},
	editor = {Rand, David and Young, Lai-Sang},
	file = {takens_81_detecting.pdf},
	interhash = {9e78058fabc23557b8a7b9201be0a9b8},
	intrahash = {39782de7849c029ffdd9d2d7e00c457e},
	isbn = {978-3-540-11171-9},
	keywords = {91b84-economic-time-series-analysis 35b41-pdes-attractors 62m10-time-series-auto-correlation-regression},
	pages = {366--381},
	posted-at = {2015-07-15 03:17:15},
	priority = {2},
	publisher = {Springer},
	series = {Lecture Notes in Mathematics},
	timestamp = {2021-01-19T06:16:33.000+0100},
	title = {{Detecting Strange Attractors in Turbulence}},
	url = {http://dx.doi.org/10.1007/bfb0091924},
	volume = 898,
	year = 1981
}

@misc{rabanser2017introduction,
	title={Introduction to Tensor Decompositions and their Applications in Machine Learning}, 
	author={Stephan Rabanser and Oleksandr Shchur and Stephan Günnemann},
	year={2017},
	eprint={1711.10781},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@article{HASTAD1990644,
	title = {Tensor rank is NP-complete},
	journal = {Journal of Algorithms},
	volume = {11},
	number = {4},
	pages = {644-654},
	year = {1990},
	issn = {0196-6774},
	doi = {https://doi.org/10.1016/0196-6774(90)90014-6},
	url = {https://www.sciencedirect.com/science/article/pii/0196677490900146},
	author = {Johan Håstad},
	abstract = {We prove that computing the rank of a three-dimensional tensor over any finite field is NP-complete. Over the rational numbers the problem is NP-hard.}
}

@misc{misc_human_activity_recognition_using_smartphones_240,
	author       = {Reyes-Ortiz Jorge and Anguita Davide and Ghio Alessandro and Oneto Luca and Parra Xavier},
	title        = {{Human Activity Recognition Using Smartphones}},
	year         = {2012},
	howpublished = {UCI Machine Learning Repository},
}

@article{Volterra:1928,
	title={Математическая теория борьбы за существование},
	author={Volterra, Vito},
	journal={UFN},
	volume={8},
	number={1},
	pages={13--34},
	year={1928}
}


@article{702ab909-8cb1-3c30-a5f1-ab4517d6cf1c,
	ISSN = {00129682, 14680262},
	URL = {http://www.jstor.org/stable/1912791},
	abstract = {There occurs on some occasions a difficulty in deciding the direction of causality between two related variables and also whether or not feedback is occurring. Testable definitions of causality and feedback are proposed and illustrated by use of simple two-variable models. The important problem of apparent instantaneous causality is discussed and it is suggested that the problem often arises due to slowness in recording information or because a sufficiently wide class of possible causal variables has not been used. It can be shown that the cross spectrum between two variables can be decomposed into two parts, each relating to a single causal arm of a feedback situation. Measures of causal lag and causal strength can then be constructed. A generalisation of this result with the partial cross spectrum is suggested.},
	author = {C. W. J. Granger},
	journal = {Econometrica},
	number = {3},
	pages = {424--438},
	publisher = {[Wiley, Econometric Society]},
	title = {Investigating Causal Relations by Econometric Models and Cross-spectral Methods},
	urldate = {2024-01-24},
	volume = {37},
	year = {1969}
}

@ARTICLE{2012Sci...338..496S,
	author = {{Sugihara}, George and {May}, Robert and {Ye}, Hao and {Hsieh}, Chih-hao and {Deyle}, Ethan and {Fogarty}, Michael and {Munch}, Stephan},
	title = "{Detecting Causality in Complex Ecosystems}",
	journal = {Science},
	keywords = {ECOLOGY},
	year = 2012,
	month = oct,
	volume = {338},
	number = {6106},
	pages = {496},
	doi = {10.1126/science.1227079},
	adsurl = {https://ui.adsabs.harvard.edu/abs/2012Sci...338..496S},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inbook{VAR_model1,
	author = {Asteriou, Dimitrios and Hall, Stephen},
	year = {2016},
	month = {01},
	pages = {333-346},
	title = {Vector Autoregressive (VAR) Models and Causality Tests},
	isbn = {978-1-137-41546-2},
	doi = {10.1057/978-1-137-41547-9_15}
}

@article{doi:10.1080/01621459.1962.10480664,
	author = {Arnold Zellner},
	title = {An Efficient Method of Estimating Seemingly Unrelated Regressions and Tests for Aggregation Bias},
	journal = {Journal of the American Statistical Association},
	volume = {57},
	number = {298},
	pages = {348-368},
	year = {1962},
	publisher = {Taylor & Francis},
	doi = {10.1080/01621459.1962.10480664},
	URL = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1962.10480664},
	eprint = {https://www.tandfonline.com/doi/pdf/10.1080/01621459.1962.10480664}
}

@article{ZHANG2023143,
	title = {Robust recurrent neural networks for time series forecasting},
	journal = {Neurocomputing},
	volume = {526},
	pages = {143-157},
	year = {2023},
	issn = {0925-2312},
	doi = {https://doi.org/10.1016/j.neucom.2023.01.037},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231223000462},
	author = {Xueli Zhang and Cankun Zhong and Jianjun Zhang and Ting Wang and Wing W.Y. Ng},
	keywords = {Recurrent neural networks (RNNs), Localized stochastic sensitivity (LSS), Time series forecasting},
	abstract = {Recurrent neural networks (RNNs) are widely utilized in time series forecasting tasks. In practical applications, there are noises in real-life time series data. A model’s generalization capacity will be diminished by model uncertainty with regard to input noises. However, the robustness of RNNs with respect to input noises has not been well studied yet. The localized stochastic sensitivity (LSS), which measures output disturbances with respect to input perturbations of learning models, has been successfully applied to improve the robustness of different neural networks on tabular and image data. But its effectiveness on time series data has not been explored. Therefore, we extend the idea of LSS and apply it to the robust RNNs training for time series forecasting problems. With the minimization of LSS, output sensitivities of RNNs with respect to small perturbations are reduced. So, the proposed robust RNNs will not be affected by slight input noises. We have used the LSTM as an example for theoretical analysis and analyzed the effectiveness of LSS on several RNN variants including the vanilla RNN, the gated recurrent unit (GRU), the long-short-term memory (LSTM), and the bi-directional long short-term memory (Bi-LSTM) in empirical studies. Experimental results confirm the efficiency of applying LSS to enhance the robustness of RNNs for time series data. For example, the robust RNNs outperform their counterpart by 53.26 and 49.45 on average in terms of Root Mean Squared Error and R-Square on five datasets.}
}

@article{HEWAMALAGE2021388,
	title = {Recurrent Neural Networks for Time Series Forecasting: Current status and future directions},
	journal = {International Journal of Forecasting},
	volume = {37},
	number = {1},
	pages = {388-427},
	year = {2021},
	issn = {0169-2070},
	doi = {https://doi.org/10.1016/j.ijforecast.2020.06.008},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207020300996},
	author = {Hansika Hewamalage and Christoph Bergmeir and Kasun Bandara},
	keywords = {Big data, Forecasting, Best practices, Framework},
	abstract = {Recurrent Neural Networks (RNNs) have become competitive forecasting methods, as most notably shown in the winning method of the recent M4 competition. However, established statistical models such as exponential smoothing (ETS) and the autoregressive integrated moving average (ARIMA) gain their popularity not only from their high accuracy, but also because they are suitable for non-expert users in that they are robust, efficient, and automatic. In these areas, RNNs have still a long way to go. We present an extensive empirical study and an open-source software framework of existing RNN architectures for forecasting, and we develop guidelines and best practices for their use. For example, we conclude that RNNs are capable of modelling seasonality directly if the series in the dataset possess homogeneous seasonal patterns; otherwise, we recommend a deseasonalisation step. Comparisons against ETS and ARIMA demonstrate that (semi-) automatic RNN models are not silver bullets, but they are nevertheless competitive alternatives in many situations.}
}

@article{TEALAB2018334,
	title = {Time series forecasting using artificial neural networks methodologies: A systematic review},
	journal = {Future Computing and Informatics Journal},
	volume = {3},
	number = {2},
	pages = {334-340},
	year = {2018},
	issn = {2314-7288},
	doi = {https://doi.org/10.1016/j.fcij.2018.10.003},
	url = {https://www.sciencedirect.com/science/article/pii/S2314728817300715},
	author = {Ahmed Tealab},
	keywords = {Forecasting, Nonlinear time series, Neural networks, Moving averages},
	abstract = {This paper studies the advances in time series forecasting models using artificial neural network methodologies in a systematic literature review. The systematic review has been done using a manual search of the published papers in the last 11 years (2006–2016) for the time series forecasting using new neural network models and the used methods are displayed. In the covered period in the study, the results obtained found 17 studies that meet all the requirements of the search criteria. Only three of the obtained proposals considered a process different to the autoregressive of a neural networks model. These results conclude that, although there are many studies that presented the application of neural network models, but few of them proposed new neural networks models for forecasting that considered theoretical support and a systematic procedure in the construction of model. This leads to the importance of formulating new models of neural networks.}
}

@article{neco,
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	title = {Long Short-Term Memory},
	journal = {Neural Computation},
	volume = {9},
	number = {8},
	pages = {1735-1780},
	year = {1997},
	month = {11},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	issn = {0899-7667},
	doi = {10.1162/neco.1997.9.8.1735},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	eprint = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf},
}

@article{1572261550523548160,
	author="KRIM, Hamid",
	title="Two Decades of Array Signal Processing Research",
	journal="IEEE Signal Processing Magazine",
	year="1994",
	volume="0",
	pages="67-94",
	URL="https://cir.nii.ac.jp/crid/1572261550523548160"
}

@article{mSSA_overview,
	author = {Hassani, Hossein and Mahmoudvand, Rahim},
	year = {2013},
	month = {04},
	pages = {},
	title = {Multivariate singular spectrum analysis: A general view and new vector forecasting approach},
	volume = {01},
	journal = {International Journal of Energy and Statistics},
	doi = {10.1142/S2335680413500051}
}

@article{kolda_tensors,
	author = {Kolda, Tamara and Bader, Brett},
	year = {2009},
	month = {08},
	pages = {455-500},
	title = {Tensor Decompositions and Applications},
	volume = {51},
	journal = {SIAM Review},
	doi = {10.1137/07070111X}
}

@book{van1981another,
	title={Another NP-complete partition problem and the complexity of computing short vectors in a lattice},
	author={van Emde-Boas, P.},
	series={Report. Department of Mathematics. University of Amsterdam},
	year={1981},
	publisher={Department, Univ.}
}

@Inbook{Grafarend2022,
	author="Grafarend, Erik
	and Zwanzig, Silvelyn
	and Awange, Joseph",
	title="Integer Least Squares",
	bookTitle="Applications of Linear and Nonlinear Models: Fixed Effects, Random Effects, and Total Least Squares",
	year="2022",
	publisher="Springer International Publishing",
	address="Cham",
	pages="579--603",
	abstract="In this chapter the general mixed integer linear model is introduced and its background in application for the Global Navigation Satellite Systems (GNSS) is described. The fitting of such models is reduced to the integer least squares problem. The principles of solving integer least squares problem are explained and the LLL algorithm is presented.",
	isbn="978-3-030-94598-5",
	doi="10.1007/978-3-030-94598-5_16",
	url="https://doi.org/10.1007/978-3-030-94598-5_16"
}

@techreport{BolusaniEtal2024ZR,
	author = {Suresh Bolusani and Mathieu Besan{\c{c}}on and Ksenia Bestuzheva and Antonia Chmiela and Jo{\~{a}}o Dion{\'{i}}sio and Tim Donkiewicz and Jasper van Doornmalen and Leon Eifler and Mohammed Ghannam and Ambros Gleixner and Christoph Graczyk and Katrin Halbig and Ivo Hedtke and Alexander Hoen and Christopher Hojny and Rolf van der Hulst and Dominik Kamp and Thorsten Koch and Kevin Kofler and Jurgen Lentz and Julian Manns and Gioni Mexi and Erik~M\"{u}hmer and Marc E. Pfetsch and Franziska Schl{\"o}sser and Felipe Serrano and Yuji Shinano and Mark Turner and Stefan Vigerske and Dieter Weninger and Lixing Xu},
	title = {{The SCIP Optimization Suite 9.0}},
	type = {ZIB-Report},
	institution = {Zuse Institute Berlin},
	month = {February},
	year = {2024},
	number = {24-02-29},
	url = {https://nbn-resolving.org/urn:nbn:de:0297-zib-95528}
}